{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e13063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install(name):\n",
    "    subprocess.call(['pip', 'install', name])\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import textstat\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, cross_val_predict, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from bnlp import POS,NER\n",
    "from bnlp.corpus import stopwords\n",
    "from bnlp import NLTKTokenizer\n",
    "try:\n",
    "\tfrom bangla_stemmer.stemmer import stemmer\n",
    "except:\n",
    "\tinstall('bangla-stemmer')\n",
    "\tfrom bangla_stemmer.stemmer import stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "try:\n",
    "\tfrom pydrive.auth import GoogleAuth\n",
    "\tfrom pydrive.drive import GoogleDrive\n",
    "except:\n",
    "\tinstall('pydrive')\n",
    "\tfrom pydrive.auth import GoogleAuth\n",
    "\tfrom pydrive.drive import GoogleDrive\n",
    "\n",
    "def LABSE_Embedding(c, Lang):\n",
    "\tif Lang == 'Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tsentences=bnltk.sentence_tokenize(c)\n",
    "\telse:\n",
    "\t\tsentences=nltk.sent_tokenize(c)\n",
    "\tmodel = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "\tembeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\treturn embeddings,sentences\n",
    "\n",
    "def LABSE_SemanticSimilarity(c1,c2, Lang):\n",
    "    B_Embedding1,sentences1=LABSE_Embedding(c1, Lang)\n",
    "    B_Embedding2,sentences2=LABSE_Embedding(c2, Lang)\n",
    "    #Compute cosine-similarities\n",
    "    cosine_scores = util.cos_sim(B_Embedding1, B_Embedding2)\n",
    "    values, indices=cosine_scores.max(axis=1)\n",
    "    #for i in range(len(sentences1)):\n",
    "    #    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[indices[i]], values[i]))\n",
    "    \n",
    "    mean_sim=values.mean().item()\n",
    "    #print(\"Average of Maximum Similarity:\", mean_sim)\n",
    "    return mean_sim\n",
    "\n",
    "\n",
    "def readability(c, Lang=\"En\"):\n",
    "    F=[]\n",
    "    F.append(textstat.flesch_reading_ease(c))\n",
    "    F.append(textstat.flesch_kincaid_grade(c))\n",
    "    F.append(textstat.smog_index(c))\n",
    "    F.append(textstat.coleman_liau_index(c))\n",
    "    F.append(textstat.automated_readability_index(c))\n",
    "    F.append(textstat.dale_chall_readability_score(c))\n",
    "    F.append(textstat.difficult_words(c))\n",
    "    F.append(textstat.linsear_write_formula(c))\n",
    "    F.append(textstat.gunning_fog(c))\n",
    "    #F.append(textstat.text_standard(c))\n",
    "    F.append(textstat.fernandez_huerta(c))\n",
    "    F.append(textstat.szigriszt_pazos(c))\n",
    "    F.append(textstat.gutierrez_polini(c))\n",
    "    F.append(textstat.crawford(c))\n",
    "    F.append(textstat.gulpease_index(c))\n",
    "    ####F.append(textstat.osman(c)) ------------------> Bk\n",
    "    return F\n",
    "    \n",
    "\n",
    "def read_file(flname):\n",
    "\tfp=open(flname,'rb')\n",
    "\tc=fp.read()\n",
    "\tn=c.decode()\n",
    "\tfp.close()\n",
    "\treturn n\n",
    "def Read_config():\n",
    "    fp=open('C:\\\\Users\\\\RITUJA\\\\Desktop\\\\AuthorshipAttributionFeatures\\\\config.txt')\n",
    "    n=fp.read()\n",
    "    f=n.replace('\\n',' ')\n",
    "    return eval (f)\n",
    "\n",
    "def count_words(c, Lang=\"En\"):\n",
    "\tif Lang == 'Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tL=len(bnltk.word_tokenize(c))\n",
    "\telse:\n",
    "\t\tL=len(nltk.word_tokenize(c))\n",
    "\treturn L\n",
    "\n",
    "def count_lines(c, Lang=\"En\"):\n",
    "\tif Lang == 'Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tL=len(bnltk.sentence_tokenize(c))\n",
    "\telse:\n",
    "\t\tL=len(nltk.sent_tokenize(c))\n",
    "\treturn L\n",
    "\n",
    "def count_unique_words(c, Lang=\"En\"):\n",
    "\tif Lang == 'Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tL=len(set(bnltk.word_tokenize(c)))\n",
    "\telse:\n",
    "\t\tL=len(set(nltk.word_tokenize(c)))\n",
    "\treturn L\n",
    "\n",
    "def POS_tag_Prob_Dist(c,Lang='En'):\n",
    "\tPST=[]\n",
    "\tif Lang=='Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tL1=len(bnltk.word_tokenize(c))\n",
    "\t\tbn_pos = POS()\n",
    "\t\tmodel_path = \"C:\\\\Users\\\\RITUJA\\\\Desktop\\\\AuthorshipAttributionFeatures\\\\model\\\\bn_pos.pkl\"\n",
    "\t\tL= bn_pos.tag(model_path, c)\n",
    "\t\t#print(L)\n",
    "\t\tthe_count = Counter(tag for _, tag in L)\n",
    "\t\tTS=sum(the_count.values())\n",
    "\t\tBL= [ 'O','ALC','VAUX','NC','NP','NV','NST','PP','PPR','PRF','PRC','PRL','PWH','DAB','DRL','DWH','JJ','JQ','JINT','VM','VA','AMN','LPR','LPS','LFU','PPC','CSB','CIN','CCD','CCL','AGR','EMP','TOP','DLIM','HON','NEG','EXCL','TERM','DUB','SIM','INCL','COM','CX','NUMR','NUMS','NUMC','NUMO','RDP','RDF','RDS','UNK','PU']\n",
    "\t\t#print(BL)\n",
    "\t\tfor t in BL:\n",
    "\t\t\tPST.append(the_count[t]/TS)\n",
    "\telse:\n",
    "\t\tL1=nltk.word_tokenize(c) #-----------> Bk\n",
    "\t\tL=nltk.pos_tag(L1)\n",
    "\t\tprint(L)\n",
    "\t\tthe_count = Counter(tag for _, tag in L)\n",
    "\t\tTS=sum(the_count.values())\n",
    "\t\tEL=['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP','SYM','TO','UH','VB','VBD','VBG','VBN','VBP','VBZ','WDT','WP','WP$','WRB']\n",
    "\t\tfor t in EL:\n",
    "\t\t\tPST.append(the_count[t]/TS)\n",
    "\treturn PST\n",
    "    \n",
    "def cosine_similarity(L1,L2):\n",
    "\tcos_sim=dot(L1,L2)/(norm(L1)*norm(L2))\n",
    "\treturn cos_sim\n",
    "\n",
    "def NovelWords(c, Lang=\"En\"):\n",
    "\tU=count_unique_words(c, Lang)\n",
    "\tT=count_words(c, Lang)\n",
    "\treturn [U/T]\n",
    "\n",
    "def Count_punctuations(c,Lang='En'):\n",
    "\tPUNC = []\n",
    "\tif Lang=='Bn':\n",
    "\t\tpuncBL=['@', '!', ':', ';', ',', '#', '$', '%', '^', '(',')','ред', '&', '*', '_', \"'\",'`', '-', '~', '{','}', '.', '?', '/','\\\\']\n",
    "\t\tfor p in puncBL:\n",
    "\t\t\tPUNC.append(c.count(p)/count_words(c,Lang))\n",
    "\telse:\n",
    "\t\tpuncEN=['!','\"','#','$','%','&','(',')','*','+', '-','.','/',':',';','<','=','>','?','[',']','@','/','\\\\','^','_','`','{','}','~','|']\n",
    "\t\tfor p in puncEN:\n",
    "\t\t\t\tPUNC.append(c.count(p)/count_words(c,Lang))\n",
    "\treturn PUNC\n",
    "\n",
    "def AvgSentenceLength(c, Lang=\"En\"):\n",
    "\tif Lang == 'Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tLns=bnltk.sentence_tokenize(c)\n",
    "\telse:\n",
    "\t\tLns=nltk.sent_tokenize(c)\n",
    "\tnum_of_sen=len(Lns)\n",
    "        \n",
    "\tsen_len=0 #Number of words in a sentence\n",
    "\tfor l in Lns:\n",
    "\t\tsen_len+=count_words(l,Lang)\n",
    "\treturn [sen_len/num_of_sen]\n",
    "\n",
    "def BOW(c1,c2):\n",
    "\tcv = CountVectorizer()\n",
    "\tX = np.array(cv.fit_transform([c1,c2]).todense())\n",
    "\treturn X\n",
    "\n",
    "def FeatureVector(c, Lang,Cfg):\n",
    "\tFv=[]\n",
    "\tfor i in Cfg:\n",
    "\t\tif i[1]:\n",
    "\t\t\tFv+=i[0](c,Lang)\n",
    "\treturn Fv\n",
    "def NER_tag_Prob_Dist(c,Lang='En'):\n",
    "\tNERST=[]\n",
    "\tif Lang=='Bn':\n",
    "\t\tbnltk=NLTKTokenizer()\n",
    "\t\tL1=len(bnltk.word_tokenize(c))\n",
    "\t\tbn_ner = NER()\n",
    "\t\tmodel_path = \"C:\\\\Users\\\\RITUJA\\\\Desktop\\\\AuthorshipAttributionFeatures\\\\model\\\\bn_pos.pkl\"\n",
    "\t\tL= bn_ner.tag(model_path, c)\n",
    "\t\t#print(L)\n",
    "\t\tthe_count = Counter(tag for _, tag in L)\n",
    "\t\tTS=sum(the_count.values())\n",
    "\t\tNERBL=['O','B-PER','I-PER','E-PER','S-PER','B-ORG','I-ORG','E-ORG','S-ORG','B-LOC','I-LOC','E-LOC','S-LOC']\n",
    "\t\t#print(NERBL)\n",
    "\t\tfor t in NERBL:\n",
    "\t\t\tNERST.append(the_count[t]/TS)\n",
    "\telse:\n",
    "\t\tL1=nltk.word_tokenize(c)\n",
    "\t\ttagging=nltk.pos_tag(L1)\n",
    "\t\tL=nltk.ne_chunk(tagging) \n",
    "\t\tL1=[(ne.leaves()[0][0],ne.label()) for ne in L if type(ne) == nltk.Tree]\n",
    "\t\tthe_count = Counter(tag for _, tag in L1)      \n",
    "\t\tTS=sum(the_count.values())\n",
    "\t\tNEREL=['B-PER','I-PER','E-PER','S-PER','B-ORG','I-ORG','E-ORG','S-ORG','B-LOC','I-LOC','E-LOC','S-LOC']\n",
    "\t\tfor t in NEREL:\n",
    "\t\t\tNERST.append(the_count[t]/TS)\n",
    "\treturn NERST\n",
    "\n",
    "def Stemming_Dist(c,Lang='En'):\n",
    "    stmLs=[]\n",
    "    if Lang=='Bn':\n",
    "        bnltk=NLTKTokenizer()\n",
    "        L=bnltk.word_tokenize(c)\n",
    "        stmr = stemmer.BanglaStemmer()\n",
    "        stmLs=[stmr.stem(word) for word in L]\n",
    "    else:\n",
    "        L=nltk.word_tokenize(c)\n",
    "        ps=PorterStemmer()\n",
    "        stmLs=[ps.stem(word) for word in L]\n",
    "        \n",
    "    return stmLs\n",
    "\n",
    "def FindSimilarity(QueryPath, DocPath, Lang):\n",
    "\tLst,X=[], [[0],[0]]\n",
    "\tc1= read_file(QueryPath)\n",
    "\tCfg=Read_config()\n",
    "\n",
    "\tfor (root,dirs,files) in os.walk(DocPath, topdown=True):\n",
    "\t\tfor file in files:\t\n",
    "\t\t\tDocPathFull=os.path.join(root,file)\n",
    "\t\t\tif Path(QueryPath) == Path(DocPathFull): \n",
    "\t\t\t\tprint(\"Not Comparing with same file ...\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tc2= read_file(DocPathFull)\n",
    "\t\t\tif Cfg[1]['BOW']:\n",
    "\t\t\t\tif Cfg[0]['Stemming_Dist']:\n",
    "\t\t\t\t\tX=BOW(\" \".join(Stemming_Dist(c1)),\" \".join(Stemming_Dist(c2)))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tX=BOW(c1,c2)\n",
    "\t\t\tL1=FeatureVector(c1,Lang,Cfg[2:]) + list( X[0])\n",
    "\t\t\tL2=FeatureVector(c2, Lang,Cfg[2:]) + list( X[1])\n",
    "\t\t\tSyntactic_Similarity=cosine_similarity(L1,L2)\n",
    "\t\t\tif Cfg[1]['LABSE_SemanticSimilarity']:\n",
    "\t\t\t\t\t\t\tSemantic_Similarity=LABSE_SemanticSimilarity(c1,c2, Lang)\n",
    "\t\t\t\t\t\t\tif math.isnan(Syntactic_Similarity) : Similarity_Score=Semantic_Similarity\n",
    "\t\t\t\t\t\t\telse: Similarity_Score=(Syntactic_Similarity+Semantic_Similarity)/2\n",
    "\t\t\telse:\n",
    "\t\t\t\tSimilarity_Score= Syntactic_Similarity\n",
    "\t\t\tLst.append([Similarity_Score,DocPathFull])\n",
    "\t\t\tLst.sort(reverse=True)\n",
    "\tLst=np.array(Lst, dtype=object)\n",
    "\treturn Lst[:,0].mean(), Lst\n",
    "\n",
    "\n",
    "\n",
    "def Evaluations(MyPath,DirsLs,flname,Lang = 'Bn'):\n",
    "    import csv\n",
    "    rows=[]\n",
    "    cnt=0\n",
    "    T=0\n",
    "    fp=open('C:\\\\Users\\\\RITUJA\\\\Desktop\\\\AuthorshipAttributionFeatures\\\\config.txt')\n",
    "    n=fp.read()\n",
    "    conf=Read_config()\n",
    "    fp.close()\n",
    "\t\n",
    "    for d in DirsLs:  \n",
    "           for (root,dirs,files) in os.walk(os.path.join(MyPath,d), topdown=True):\n",
    "                for file in files:\n",
    "                    QueryPathFull=os.path.join(root,file)\n",
    "                    SimScore=[]\n",
    "                    TmpResult=[]\n",
    "                    for d1 in DirsLs:\n",
    "                        DocPath=os.path.join(MyPath,d1)\n",
    "                        #print(QueryPathFull, \"<-->\", DocPath+\"\\\\\")\n",
    "                        AvgSim,Vals=FindSimilarity(QueryPathFull,DocPath,Lang)\n",
    "                        #AvgSim=random.random()\n",
    "                        SimScore+=[AvgSim]\n",
    "                    #print(d,SimScore)\n",
    "                    Label=False\n",
    "                    if d == DirsLs[SimScore.index(max(SimScore))]: \n",
    "                        Label=True\n",
    "                        T+=1\n",
    "                    cnt+=1\n",
    "                        \n",
    "                    TmpResult=[QueryPathFull,conf]+SimScore+[Label]\n",
    "                    rows.append(TmpResult)\n",
    "    fields = ['FileName', 'Configuration']+DirsLs+['Prediction'] \n",
    "    #print(fields)\n",
    "    with open(str(T/cnt)+\"_\"+flname, 'w',newline='') as f:\n",
    "        # using csv.writer method from CSV package\n",
    "        write = csv.writer(f)      \n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)        \n",
    "    print(\"Accuracy: \", T/cnt)\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "def Evaluations(MyPath,DirsLs,flname,Lang = 'Bn'):\n",
    "    import csv\n",
    "    rows=[]\n",
    "    cnt=1\n",
    "    T=0\n",
    "    fp=open('C:\\\\Users\\\\RITUJA\\\\Desktop\\\\AuthorshipAttributionFeatures\\\\config.txt')\n",
    "    n=fp.read()\n",
    "    conf=Read_config()\n",
    "    fp.close()\n",
    "\t\n",
    "    for d in DirsLs:\n",
    "           for (root,dirs,files) in os.walk(os.path.join(MyPath,d), topdown=True):\n",
    "                for file in files:\n",
    "                    QueryPathFull=os.path.join(root,file)\n",
    "                    SimScore=[]\n",
    "                    TmpResult=[]\n",
    "                    for d1 in DirsLs:\n",
    "                        DocPath=os.path.join(MyPath,d1)\n",
    "                        #print(QueryPathFull, \"<-->\", DocPath+\"\\\\\")\n",
    "                        AvgSim,Vals=FindSimilarity(QueryPathFull,DocPath,Lang)\n",
    "                        #AvgSim=random.random()\n",
    "                        SimScore+=[AvgSim]\n",
    "                    #print(d,SimScore)\n",
    "                    Label=False\n",
    "                    if d == DirsLs[SimScore.index(max(SimScore))]: \n",
    "                        Label=True\n",
    "                        T+=1\n",
    "                    cnt+=1\n",
    "                        \n",
    "                    TmpResult=[QueryPathFull,conf]+SimScore+[Label]\n",
    "                    rows.append(TmpResult)\n",
    "    fields = ['FileName', 'Configuration']+DirsLs+['Prediction'] \n",
    "    #print(fields)\n",
    "    with open(flname, 'w',newline='') as f:\n",
    "        # using csv.writer method from CSV package\n",
    "        write = csv.writer(f)      \n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)        \n",
    "    print(\"Accuracy: \", T/cnt)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def EvaluateModel():\n",
    "    import os\n",
    "    import random\n",
    "    import csv\n",
    "    MyPath= \"C:\\\\Users\\\\RITUJA\\\\Desktop\\\\NLTR\"\n",
    "    DirsLs=[\n",
    "\t\"Aparupa Dasgupta\",\n",
    "\t\"Safia Pailan\",    \n",
    "    ]\n",
    "    flname= 'D://Evaluation.csv'\n",
    "    Result=Evaluations(MyPath,DirsLs,flname)\n",
    "    #print(Result)\n",
    "\n",
    "\n",
    "def CreateCSV():\n",
    "\tCfg=Read_config()\n",
    "\tLs=[]\n",
    "\tLang=\"Bn\"\n",
    "\tDocPath=\"C:\\\\Users\\\\RITUJA\\\\NLTR\\\\\"\n",
    "\tFields = []\n",
    "\n",
    "\tBL= [ 'O','ALC','VAUX','NC','NP','NV','NST','PP','PPR','PRF','PRC','PRL','PWH','DAB','DRL','DWH','JJ','JQ','JINT','VM','VA','AMN','LPR','LPS','LFU','PPC','CSB','CIN','CCD','CCL','AGR','EMP','TOP','DLIM','HON','NEG','EXCL','TERM','DUB','SIM','INCL','COM','CX','NUMR','NUMS','NUMC','NUMO','RDP','RDF','RDS','UNK','PU']\n",
    "\n",
    "\tpuncBL=['@', '!', ':', ';', ',', '#', '$', '%', '^', '(',')','|', '&', '*', '_', \"'\",'`', '-', '~', '{','}', '.', '?', '/','\\\\']\n",
    "\n",
    "\tNERBL=['O','B-PER','I-PER','E-PER','S-PER','B-ORG','I-ORG','E-ORG','S-ORG','B-LOC','I-LOC','E-LOC','S-LOC']\n",
    "    \n",
    "\tRL=['flesch_reading_ease','flesch_kincaid_grade','smog_index','coleman_liau_index','automated_readability_index','dale_chall_readability_score','difficult_words','linsear_write_formula','gunning_fog','fernandez_huerta','szigriszt_pazos','gutierrez_polini','crawford','gulpease_index']\n",
    "\n",
    "\n",
    "\tfor Config in Cfg:\n",
    "\t\tif isinstance(Config, dict):\n",
    "\t\t\tfor key, value in Config.items():\n",
    "\t\t\t\tif value == 1:\n",
    "\t\t\t\t\tFields.append(key)\n",
    "\t\telif isinstance(Config, tuple):\n",
    "\t\t\tfield, value = Config\n",
    "\t\t\tif value == 1:\n",
    "\t\t\t\tif field.__name__ == 'NER_tag_Prob_Dist':\n",
    "\t\t\t\t\tFields += NERBL\n",
    "\t\t\t\telif field.__name__ == 'readability':\n",
    "\t\t\t\t\tFields += RL\n",
    "\t\t\t\telif field.__name__ == 'POS_tag_Prob_Dist':\n",
    "\t\t\t\t\tFields += BL \n",
    "\t\t\t\telif field.__name__ == 'Count_punctuations':\n",
    "\t\t\t\t\tFields += puncBL\n",
    "\t\t\t\telse:Fields.append(field.__name__)\n",
    "\n",
    "                \n",
    "\tFields += ['Author', 'Filename'] \n",
    "\tprint(Fields)                \n",
    "\tfor root,dr,files in os.walk(DocPath):\n",
    "\t\tfor f in files:\n",
    "\t\t\tflnm=os.path.join(root,f)\n",
    "\t\t\t#print(flnm)\n",
    "\t\t\tdrnm=flnm.split(\"\\\\\")\n",
    "\t\t\tdrnm=drnm[drnm.index(\"NLTR\")+1]\n",
    "\t\t\t#print(drnm)\n",
    "\t\t\tc=read_file(flnm)\n",
    "\t\t\tFV=FeatureVector(c, Lang,Cfg[2:])\n",
    "\t\t\tls=FV+[drnm]+[\"\\\\\".join(flnm.split(\"\\\\\")[-2:])]\n",
    "# \t\t\tprint(ls)\n",
    "\t\t\tLs.append(ls)\n",
    "\twith open(\"D:\\\\sample_result.csv\",\"w\") as f:\n",
    "\t\twriter_object=csv.writer(f)\n",
    "# \t\tFields=[i.encode(\"utf-8\") for i in Fields]\n",
    "\t\twriter_object.writerow(Fields)\n",
    "\t\twriter_object.writerows(Ls)\n",
    "\tprint(Ls)\n",
    "\tprint(writer_object)\n",
    "    \n",
    "\n",
    "def VisualizeScatter(flname,fx,fy):\n",
    "    import pandas as pd \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import mplcursors\n",
    "    np.random.seed(42)\n",
    "    df=pd.read_csv(flname)\n",
    "\n",
    "    sns.set(style=\"darkgrid\")\n",
    "\n",
    "    sns.relplot(x=fx, y=fy, hue=\"Author\", data=df);\n",
    "    plt.savefig(\"D://FeatureComp.png\")\n",
    "    fig, ax = plt.subplots()\n",
    "    author_colors = {author: i for i, author in enumerate(df['Author'].unique())}\n",
    "    colors = df['Author'].map(author_colors)\n",
    "\n",
    "    ax.scatter(df[fx], df[fy], c=colors)\n",
    "    ax.set_title(\"Hover effect\")\n",
    "    crs = mplcursors.cursor(ax, hover=True)\n",
    "    def format_annotation(sel):\n",
    "        index = sel.target.index\n",
    "        point = df.iloc[index]\n",
    "        text = 'Author: {}\\nfx: {}\\nfy: {}'.format(\n",
    "            point['Author'], point[fx], point[fy])\n",
    "        sel.annotation.set_text(text)\n",
    "\n",
    "    crs.connect(\"add\", format_annotation)\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def generate_prediction(model_type):\n",
    "    existing_data = pd.read_csv('D:\\\\sample_result.csv', skip_blank_lines=True).dropna()\n",
    "\n",
    "    features = ['NovelWords', 'AvgSentenceLength', 'flesch_reading_ease', 'flesch_kincaid_grade',\n",
    "                'smog_index', 'coleman_liau_index', 'automated_readability_index', 'dale_chall_readability_score',\n",
    "                'difficult_words', 'linsear_write_formula', 'gunning_fog', 'fernandez_huerta',\n",
    "                'szigriszt_pazos', 'gutierrez_polini', 'crawford', 'gulpease_index']\n",
    "\n",
    "    X = existing_data[features]\n",
    "    y = existing_data['Author']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "    if model_type == 'Logistic Regression':\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "    elif model_type == 'Random Forest Classifier':\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    else:\n",
    "        print(\"Invalid model type.\")\n",
    "        return None\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=None)\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    accuracy = cv_scores.mean() * 100\n",
    "\n",
    "    df = pd.read_csv('D:\\\\samp_result.csv', skip_blank_lines=True).dropna()\n",
    "    X_test = df[features]\n",
    "    y_test = df['Author']\n",
    "    pred = clf.predict(X_test)\n",
    "    pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(y_train)\n",
    "\n",
    "    pred_label_indices = label_encoder.transform(pred)\n",
    "    pred_author_names = label_encoder.inverse_transform(pred_label_indices)\n",
    "#     print(\"Authors Names:\",y.unique())  \n",
    "#     print(\"Scores:\", cv_scores)\n",
    "    cvas = {}\n",
    "    for author, score in zip(y.unique(), cv_scores):\n",
    "        cvas[author] = score\n",
    "\n",
    "    print(\"Cross Validation Accuracy Scores:\", cvas)\n",
    "\n",
    "    print(\"Accuracy: %.2f%%\" % accuracy)\n",
    "    train_pred = clf.predict(X_train)\n",
    "    train_report = classification_report(y_train, train_pred)\n",
    "    print(\"Classification Report (Training Dataset):\\n\", train_report)\n",
    "    print(\"Prediction:\", pred_author_names)\n",
    "\n",
    "    probabilities = {}\n",
    "    for author, probs in zip(clf.classes_, pred_proba[0]):\n",
    "        probabilities[author] = f\"{probs:.4f}\"\n",
    "\n",
    "    print(\"Probabilities:\", probabilities)\n",
    "\n",
    "    return cvas, accuracy, train_report, pred_author_names, pred_proba\n",
    "\n",
    "def generate_plot(text, fx, fy, model_type):\n",
    "    Fields = ['NovelWords', 'AvgSentenceLength', 'flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index', 'coleman_liau_index', 'automated_readability_index', 'dale_chall_readability_score', 'difficult_words', 'linsear_write_formula', 'gunning_fog', 'fernandez_huerta', 'szigriszt_pazos', 'gutierrez_polini', 'crawford', 'gulpease_index', 'Author']\n",
    "    Lang = \"Bn\"\n",
    "    c = text\n",
    "    Cfg = Read_config()\n",
    "    FV = FeatureVector(c, Lang, Cfg[2:])\n",
    "    ls = FV + [\"Query\"]\n",
    "    with open(\"D:\\\\samp_result.csv\", \"w\", newline='') as f:\n",
    "        writer_object = csv.writer(f)\n",
    "        writer_object.writerow(Fields)\n",
    "        writer_object.writerow(ls)\n",
    "\n",
    "    if fx and fy:\n",
    "        existing_data = pd.read_csv('D:\\\\sample_result.csv', skip_blank_lines=True).dropna()\n",
    "        df = pd.read_csv('D:\\\\samp_result.csv', skip_blank_lines=True).dropna()\n",
    "        new_x = df[fx]\n",
    "        new_y = df[fy]\n",
    "        combined_x = pd.concat([existing_data[fx], new_x])\n",
    "        combined_y = pd.concat([existing_data[fy], new_y])\n",
    "        #print(existing_data['Author'])\n",
    "        combined_colors = pd.concat([existing_data['Author'], df['Author']])\n",
    "        author_colors = {author: i for i, author in enumerate(combined_colors.unique())}\n",
    "        print(author_colors.keys())\n",
    "        \n",
    "        legend_labels = list(author_colors.keys())\n",
    "        legend_handles = []\n",
    "        for i,label in enumerate(legend_labels):\n",
    "            color = plt.cm.tab10(author_colors[label]) \n",
    "            legend_handles.append(plt.Line2D([0], [0], marker='o', color=color, label=label, markersize=8))\n",
    "\n",
    "        author_colors1 = {author: plt.cm.tab10(author_colors[author]) for author in combined_colors.unique()}\n",
    "        colors = combined_colors.map(author_colors1)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(combined_x, combined_y, c=colors) \n",
    "        ax.set_title(\"Combined Plot\")\n",
    "        ax.set_xlabel(fx)\n",
    "        ax.set_ylabel(fy)\n",
    "\n",
    "        crs = mplcursors.cursor(scatter)\n",
    "\n",
    "        def format_annotation(sel):\n",
    "            index = sel.target.index\n",
    "            point = pd.concat([existing_data, df]).iloc[index]\n",
    "            text = 'Author: {}\\n{}: {}\\n{}: {}'.format(point['Author'], fx, point[fx], fy, point[fy])\n",
    "            sel.annotation.set_text(text)\n",
    "\n",
    "        crs.connect(\"add\", format_annotation)\n",
    "        \n",
    "\n",
    "        ax.legend(handles=legend_handles, loc='best')\n",
    "\n",
    "        #ax.legend()\n",
    "        plt.savefig('D://image.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Please provide values for fx and fy.\")\n",
    "\n",
    "def CSVandCombinedPlot(model_type):\n",
    "    import tkinter as tk\n",
    "    from tkinter import Tk,filedialog\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    \n",
    "    def browse_file():\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        file_path = filedialog.askopenfilename()\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        text_area.value = text\n",
    "    \n",
    "    fields = ['NovelWords', 'AvgSentenceLength', 'flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index', 'coleman_liau_index', 'automated_readability_index', 'dale_chall_readability_score', 'difficult_words', 'linsear_write_formula', 'gunning_fog', 'fernandez_huerta', 'szigriszt_pazos', 'gutierrez_polini', 'crawford', 'gulpease_index', 'Author']\n",
    "    prediction_button = widgets.Button(description=\"Predict\")\n",
    "\n",
    "    def generate_predictions(button):\n",
    "        cvas,accuracy,train_report,pred_author_names,proba_dict = generate_prediction(model_type)\n",
    "\n",
    "    prediction_button.on_click(generate_predictions)\n",
    "\n",
    "    text_area = widgets.Textarea(value='', placeholder='Enter text here', rows=4)\n",
    "    browse_button = widgets.Button(description=\"Browse File\")\n",
    "    browse_button.on_click(lambda button: browse_file())\n",
    "\n",
    "    fx_dropdown = widgets.Dropdown(options=fields, description=\"fx:\")\n",
    "    fy_dropdown = widgets.Dropdown(options=fields, description=\"fy:\")\n",
    "    button = widgets.Button(description=\"Generate Plot\")\n",
    "\n",
    "    button.on_click(lambda button: generate_plot(text_area.value, fx_dropdown.value, fy_dropdown.value, model_type))\n",
    "\n",
    "    display(prediction_button, text_area, browse_button, fx_dropdown, fy_dropdown, button)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    from ipywidgets import interactive, Button, Textarea\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    \n",
    "    model_type_dropdown = widgets.Dropdown(options=['Logistic Regression', 'Random Forest Classifier'], description=\"Model Type:\")\n",
    "    display(model_type_dropdown)\n",
    "    \n",
    "    def model_type_selected(change):\n",
    "        model_type = change.new\n",
    "        CSVandCombinedPlot(model_type)\n",
    "\n",
    "    model_type_dropdown.observe(model_type_selected, 'value')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
